{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c7420e-f6ce-422c-97af-d8dca38350e9",
   "metadata": {},
   "source": [
    "Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose.\n",
    "\n",
    "Purpose of Simple Linear Regression:\n",
    "Simple linear regression is a statistical technique used to analyze and model the relationship between two variables – an independent variable (X) and a dependent variable (Y). Its main purpose is to predict the value of Y based on X and to understand how changes in X affect Y. By fitting a straight line, called the regression line, we can quantify this relationship using the equation:\n",
    "\n",
    "Y = b_0 + b_1 X\n",
    "\n",
    " = intercept (value of Y when X = 0)\n",
    "\n",
    " = slope (change in Y for a unit change in X)\n",
    "\n",
    "This method helps in making predictions, identifying trends, and measuring the strength and direction of the relationship between the two variables.\n",
    "\n",
    "Example: If X = number of hours studied and Y = exam score, simple linear regression can help predict the exam score based on the hours studied, and show how much improvement in score is expected for each additional hour of study.\n",
    "\n",
    "\n",
    "Question 2: What are the key assumptions of Simple Linear Regression?\n",
    "\n",
    "Key Assumptions of Simple Linear Regression:\n",
    "\n",
    "1. Linearity – The relationship between the independent variable (X) and the dependent variable (Y) is linear. The regression line correctly represents this relationship.\n",
    "2. Independence – The observations are independent of each other. The value of Y for one observation does not influence anothe\n",
    "3. Homoscedasticity – The variance of the residuals (errors) is constant across all levels of X. In other words, the spread of Y values around the regression line is roughly the same for all X values.\n",
    "4. Normality of Errors – The residuals (differences between actual Y and predicted Y) are normally distributed.\n",
    "5. No Multicollinearity (for multiple regression only) – In simple linear regression, there is only one independent variable, so this is automatically satisfied.\n",
    "\n",
    "\n",
    "Question 3: Write the mathematical equation for a simple linear regression model and\n",
    "explain each term.\n",
    "Answer:\n",
    "Mathematical Equation of Simple Linear Regression:\n",
    "\n",
    "Y = b_0 + b_1 X + \\varepsilon\n",
    "\n",
    "Explanation of each term:\n",
    "\n",
    " = Dependent variable (the outcome we want to predict)\n",
    "\n",
    " = Independent variable (the predictor)\n",
    "\n",
    " = Intercept (the value of Y when X = 0)\n",
    "\n",
    " = Slope / Regression coefficient (the change in Y for a one-unit change in X)\n",
    "\n",
    " = Error term / Residual (the difference between the observed value of Y and the predicted value)\n",
    "\n",
    "\n",
    "Summary: This equation models the relationship between X and Y using a straight line, where the slope  shows how Y changes with X, and the error term  accounts for randomness or factors not included in the model.\n",
    "\n",
    "\n",
    "Question 4: Provide a real-world example where simple linear regression can be\n",
    "applied.\n",
    "Answer:\n",
    "Real-World Example of Simple Linear Regression:\n",
    "\n",
    "One common real-world example is predicting house prices based on the size of the house.\n",
    "Independent variable (X): Size of the house in square feet\n",
    "Dependent variable (Y): Price of the house\n",
    "\n",
    "In this case, simple linear regression can help estimate how much the price of a house increases with each additional square foot. By collecting data on houses (their sizes and prices), we can fit a regression line:\n",
    "\n",
    "\\text{Price} = b_0 + b_1 \\times \\text{Size} + \\varepsilon\n",
    " = Intercept, representing the baseline price of a house even if its size were zero (theoretical starting point)\n",
    " = Slope, showing how much the price increases for every extra square foot of area\n",
    " = Error term, accounting for other factors like location, age of the house, or amenities that affect price\n",
    "\n",
    "Why this is useful:\n",
    "\n",
    "1. Real estate agents can predict house prices for new listings quickly.\n",
    "\n",
    "2. Buyers can estimate a fair price based on size.\n",
    "3. Analysts can understand the relationship between house size and price, helping in investment decisions.\n",
    "\n",
    "\n",
    "Question 5: What is the method of least squares in linear regression?\n",
    "Answer\n",
    "Method of Least Squares in Linear Regression:\n",
    "\n",
    "The method of least squares is a technique used to find the best-fitting line in a simple linear regression model. It works by minimizing the sum of the squares of the differences (errors) between the observed values and the predicted values.\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "Let the observed values be  and the predicted values from the regression line be .\n",
    "The errors (residuals) are .\n",
    "The method of least squares finds  and  such that the sum of squared errors is minimized:\n",
    "\n",
    "\\text{Minimize } \\sum_{i=1}^{n} e_i^2 = \\sum_{i=1}^{n} (Y_i - (b_0 + b_1 X_i))^2\n",
    "Why squares?\n",
    "Squaring ensures that negative and positive errors do not cancel each other.\n",
    "It gives more weight to larger errors, making the line fit better overall.\n",
    "\n",
    "Purpose:\n",
    "Using least squares, we get the most accurate estimates of the intercept () and slope (), which gives the regression line that best represents the relationship between X and Y.\n",
    "\n",
    "Example in real life:\n",
    "If predicting house prices based on size, the least squares method ensures the regression line minimizes the total prediction errors for all the houses in the dataset, giving the most reliable price estimates.\n",
    "\n",
    "Question 6: What is Logistic Regression? How does it differ from Linear Regression?\n",
    "Answer:\n",
    "\n",
    "Logistic regression is used when we want to predict a category or outcome, usually something like yes/no, pass/fail, or 0/1. Instead of giving an exact number like linear regression, it gives the probability that something will happen.\n",
    "For example, if we want to predict whether a student will pass an exam based on how many hours they studied, logistic regression can tell us the chance of passing, like 70% or 90%. It uses a curve (called the sigmoid curve) to make sure the prediction is always between 0 and 1.\n",
    "\n",
    "How it’s different from linear regression:\n",
    "\n",
    "1. Linear regression predicts actual numbers (like marks scored), logistic regression predicts probabilities or categories.\n",
    "2. Linear regression draws a straight line, logistic regression draws an S-shaped curve.\n",
    "3. Linear regression uses least squares to fit the line; logistic regression uses maximum likelihood to estimate probabilities.\n",
    "4. Linear regression can give any value; logistic regression always gives a number between 0 and 1, which makes sense for probabilities.\n",
    "\n",
    "Example:\n",
    "\n",
    "Linear regression: Predict a student’s score based on hours studied.\n",
    "Logistic regression: Predict whether the student passes or fails based on hours studied.\n",
    "\n",
    "\n",
    "In short, linear regression is for predicting numbers, logistic regression is for predicting yes/no outcomes.\n",
    "\n",
    "Question 7: Name and briefly describe three common evaluation metrics for regression\n",
    "models.\n",
    "Answer:x\n",
    "Three Common Evaluation Metrics for Regression Models:\n",
    "\n",
    "1. Mean Absolute Error (MAE):\n",
    "It measures the average of the absolute differences between the predicted values and the actual values.\n",
    "Gives an idea of how far predictions are from actual values on average.\n",
    "Formula:\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |Y_i - \\hat{Y}_i|\n",
    "\n",
    "2. Mean Squared Error (MSE):\n",
    "It measures the average of the squared differences between predicted and actual values.\n",
    "Squaring penalizes larger errors more than smaller ones.\n",
    "Formula:\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2\n",
    "\n",
    "3. R-squared (R²):\n",
    "It shows the proportion of variance in the dependent variable explained by the model.\n",
    "Ranges from 0 to 1; closer to 1 means the model explains the data well.\n",
    "Formula:\n",
    "R^2 = 1 - \\frac{\\sum (Y_i - \\hat{Y}_i)^2}{\\sum (Y_i - \\bar{Y})^2}\n",
    "\n",
    "\n",
    "\n",
    "Question 8: What is the purpose of the R-squared metric in regression analysis?\n",
    "Answer:\n",
    "Purpose of R-squared in Regression Analysis:\n",
    "R-squared (R²) is a metric that shows how well the regression model explains the variation in the dependent variable (Y). In simple words, it tells us what percentage of the changes in Y can be explained by X.\n",
    "R² ranges from 0 to 1.\n",
    "Closer to 1 → The model explains most of the variation in Y (good fit).\n",
    "Closer to 0 → The model does not explain much (poor fit).\n",
    "\n",
    "Example:\n",
    "If R² = 0.85 in a model predicting house prices from size, it means 85% of the variation in house prices can be explained by house size, and the remaining 15% is due to other factors like location, age of the house, etc.\n",
    "\n",
    "R-squared measures the goodness of fit of a regression model—it tells us how well the model captures the real relationship between X and Y.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61001207-f2bd-4f8b-bf8f-2ac71414c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b8a47a-bc9e-407c-a827-614c3f977f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope (b1): 0.6\n",
      "Intercept (b0): 2.2\n"
     ]
    }
   ],
   "source": [
    "#Question 9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n",
    "# Import required libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "# X = independent variable (e.g., hours studied)\n",
    "# Y = dependent variable (e.g., exam score)\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Reshape for sklearn\n",
    "Y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y)\n",
    "\n",
    "# Print the slope (coefficient) and intercept\n",
    "print(\"Slope (b1):\", model.coef_[0])\n",
    "print(\"Intercept (b0):\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15556c9e-dafb-4ae4-b4fb-f13df667adf9",
   "metadata": {},
   "source": [
    "Question 10: How do you interpret the coefficients in a simple linear regression model?\n",
    "Answer:\n",
    "Interpreting the Coefficients in Simple Linear Regression:\n",
    "In a simple linear regression model:\n",
    "Y = b_0 + b_1 X\n",
    " (Intercept):\n",
    "\n",
    "This is the value of Y when X = 0.\n",
    "\n",
    "It represents the starting point of the regression line on the Y-axis.\n",
    "\n",
    "Example: If predicting exam score based on hours studied,  means a student is expected to score 40 marks even if they study 0 hours.\n",
    "\n",
    "\n",
    " (Slope / Coefficient of X):\n",
    "\n",
    "This shows how much Y changes for a one-unit increase in X.\n",
    "\n",
    "Positive  → Y increases as X increases.\n",
    "\n",
    "Negative  → Y decreases as X increases.\n",
    "\n",
    "Example: If , each additional hour studied increases the expected score by 5 marks.\n",
    "\n",
    "\n",
    "\n",
    "In short:\n",
    "\n",
    "Intercept = starting point\n",
    "\n",
    "Slope = effect of X on Y\n",
    
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
